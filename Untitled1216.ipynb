{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78eac5-dc5a-4d76-9f33-5be161c2868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CHECK] val images: 114, labels: 114\n",
      "[CHECK] Class ID counts in val: {}\n",
      "[INFO] Starting training (5 epochs)...\n",
      "New https://pypi.org/project/ultralytics/8.3.179 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.161  Python-3.11.9 torch-2.2.2+cpu CPU (AMD Ryzen 7 7435HS)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\sagni\\Downloads\\Helmet Checker\\helmet_dataset.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=helmet_v8n_5ep3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1504.8669.3 MB/s, size: 534.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\train.cache... 534 images, 534 backgrounds, 0 corrupt: 100%|██████████| 534/534 [00:00<\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1656.0415.3 MB/s, size: 556.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\val.cache... 114 images, 114 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<?, ?\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        1/5         0G          0      110.1          0          0        640: 100%|██████████| 34/34 [02:07<00:00,  3.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G          0      85.83          0          0        640: 100%|██████████| 34/34 [02:05<00:00,  3.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G          0      75.68          0          0        640: 100%|██████████| 34/34 [02:04<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G          0      68.11          0          0        640: 100%|██████████| 34/34 [02:06<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G          0      63.33          0          0        640: 100%|██████████| 34/34 [02:04<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.187 hours.\n",
      "Optimizer stripped from C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\\weights\\best.pt...\n",
      "Ultralytics 8.3.161  Python-3.11.9 torch-2.2.2+cpu CPU (AMD Ryzen 7 7435HS)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:07<00:00,  1.90s/it]\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:583: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 0.8ms preprocess, 49.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\u001b[0m\n",
      "[INFO] Run directory: C:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep3\n",
      "[INFO] Validating best.pt...\n",
      "Ultralytics 8.3.161  Python-3.11.9 torch-2.2.2+cpu CPU (AMD Ryzen 7 7435HS)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2097.3289.8 MB/s, size: 611.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\val.cache... 114 images, 114 backgrounds, 0 corrupt: 100%|██████████| 114/114 [00:00<?, ?\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\labels\\val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:583: RuntimeWarning: Mean of empty slice.\n",
      "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:628: RuntimeWarning: Mean of empty slice.\n",
      "  y = smooth(py.mean(0), 0.1)\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\metrics.py:765: RuntimeWarning: Mean of empty slice.\n",
      "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        114          0          0          0          0          0\n",
      "WARNING no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 0.5ms preprocess, 45.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sagni\\Downloads\\Helmet Checker\\runs\\detect\\helmet_v8n_5ep32\u001b[0m\n",
      "[OK] Accuracy curves saved → C:\\Users\\sagni\\Downloads\\Helmet Checker\\metrics\\accuracy_curves.png\n",
      "[INFO] Confusion matrix over 114 images from C:\\Users\\sagni\\Downloads\\Helmet Checker\\data\\images\\val\n",
      "[TRY] conf=0.05, IoU=0.30 -> matches=0\n",
      "[TRY] conf=0.05, IoU=0.50 -> matches=0\n",
      "[TRY] conf=0.10, IoU=0.30 -> matches=0\n",
      "[TRY] conf=0.10, IoU=0.50 -> matches=0\n",
      "[TRY] conf=0.20, IoU=0.30 -> matches=0\n",
      "[TRY] conf=0.20, IoU=0.50 -> matches=0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# =========================\n",
    "# Config (5 epochs)\n",
    "# =========================\n",
    "ROOT = Path(r\"C:\\Users\\sagni\\Downloads\\Helmet Checker\")\n",
    "DATA_YAML = ROOT / \"helmet_dataset.yaml\"\n",
    "RUN_NAME = \"helmet_v8n_5ep\"    # run folder under runs/detect/\n",
    "BASE_MODEL = \"yolov8n.pt\"      # change to yolov8s.pt if you want\n",
    "EPOCHS = 5                     # <-- as requested\n",
    "BATCH = 16\n",
    "IMG = 640\n",
    "WORKERS = 8\n",
    "\n",
    "# Output\n",
    "OUT_DIR = ROOT / \"metrics\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==================================\n",
    "# Helpers\n",
    "# ==================================\n",
    "def load_yaml(path: Path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def plot_curves_from_df(df: pd.DataFrame, out_path: Path):\n",
    "    x_name = 'epoch' if 'epoch' in df.columns else ('thr' if 'thr' in df.columns else None)\n",
    "    if x_name is None:\n",
    "        df.insert(0, \"epoch\", np.arange(1, len(df)+1))\n",
    "        x_name = \"epoch\"\n",
    "    x = df[x_name].values\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for col, label in [\n",
    "        ('precision','Precision'),\n",
    "        ('recall','Recall'),\n",
    "        ('metrics/precision(B)','Precision'),\n",
    "        ('metrics/recall(B)','Recall'),\n",
    "        ('mAP50','mAP@50'),\n",
    "        ('mAP50-95','mAP@50-95'),\n",
    "        ('metrics/mAP50(B)','mAP@50'),\n",
    "        ('metrics/mAP50-95(B)','mAP@50-95'),\n",
    "        ('fitness','Fitness'),\n",
    "    ]:\n",
    "        if col in df.columns:\n",
    "            plt.plot(x, df[col].values, marker='o', linewidth=2, label=label)\n",
    "    plt.xlabel('Epoch' if x_name=='epoch' else 'Confidence threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Training / Validation Metrics')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=180)\n",
    "    plt.close()\n",
    "    print(f\"[OK] Accuracy curves saved → {out_path}\")\n",
    "\n",
    "def yolo_txt_to_boxes(txt_path: Path, img_w: int, img_h: int):\n",
    "    boxes, labels = [], []\n",
    "    if not txt_path.exists():\n",
    "        return np.zeros((0, 4), dtype=np.float32), np.zeros((0,), dtype=np.int32)\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5: \n",
    "                continue\n",
    "            c = int(float(parts[0]))\n",
    "            cx = float(parts[1]) * img_w\n",
    "            cy = float(parts[2]) * img_h\n",
    "            w  = float(parts[3]) * img_w\n",
    "            h  = float(parts[4]) * img_h\n",
    "            x1 = cx - w/2; y1 = cy - h/2\n",
    "            x2 = cx + w/2; y2 = cy + h/2\n",
    "            labels.append(c)\n",
    "            boxes.append([x1,y1,x2,y2])\n",
    "    return np.array(boxes, dtype=np.float32), np.array(labels, dtype=np.int32)\n",
    "\n",
    "def imread_size(path: Path):\n",
    "    from PIL import Image\n",
    "    with Image.open(path) as im:\n",
    "        return im.size  # (w,h)\n",
    "\n",
    "def box_iou_xyxy(a, b):\n",
    "    N, M = a.shape[0], b.shape[0]\n",
    "    if N == 0 or M == 0:\n",
    "        return np.zeros((N, M), dtype=np.float32)\n",
    "    ix1 = np.maximum(a[:, None, 0], b[None, :, 0])\n",
    "    iy1 = np.maximum(a[:, None, 1], b[None, :, 1])\n",
    "    ix2 = np.minimum(a[:, None, 2], b[None, :, 2])\n",
    "    iy2 = np.minimum(a[:, None, 3], b[None, :, 3])\n",
    "    iw = np.clip(ix2 - ix1, 0, None)\n",
    "    ih = np.clip(iy2 - iy1, 0, None)\n",
    "    inter = iw * ih\n",
    "    area_a = (a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1])\n",
    "    area_b = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "    union = area_a[:, None] + area_b[None, :] - inter\n",
    "    return inter / np.clip(union, 1e-9, None)\n",
    "\n",
    "def dataset_sanity_check(data_yaml: Path, split=\"val\", class_count_expected=2):\n",
    "    data = load_yaml(data_yaml)\n",
    "    data_root = Path(data[\"path\"])\n",
    "    images_dir = data_root / f\"images/{split}\"\n",
    "    labels_dir = data_root / f\"labels/{split}\"\n",
    "\n",
    "    imgs = sorted(list(images_dir.glob(\"*.*\")))\n",
    "    lbls = sorted(list(labels_dir.glob(\"*.txt\")))\n",
    "    print(f\"[CHECK] {split} images: {len(imgs)}, labels: {len(lbls)}\")\n",
    "\n",
    "    # quick label scan\n",
    "    bad_ids = []\n",
    "    class_ids = []\n",
    "    for lp in lbls:\n",
    "        with open(lp, \"r\", encoding=\"utf-8\") as f:\n",
    "            for ln in f:\n",
    "                ps = ln.strip().split()\n",
    "                if len(ps) != 5: \n",
    "                    continue\n",
    "                cid = int(float(ps[0]))\n",
    "                class_ids.append(cid)\n",
    "                if cid < 0 or cid >= class_count_expected:\n",
    "                    bad_ids.append((lp.name, cid))\n",
    "    if bad_ids:\n",
    "        print(\"[WARN] Found label class IDs outside expected range 0..{}: (file, cid) samples below\".format(class_count_expected-1))\n",
    "        print(bad_ids[:10])\n",
    "    ctr = Counter(class_ids)\n",
    "    print(f\"[CHECK] Class ID counts in {split}: {dict(ctr)}\")\n",
    "    return len(imgs), len(lbls), dict(ctr)\n",
    "\n",
    "def run_confusion_heatmap_resilient(\n",
    "    model, data_yaml: Path, split=\"val\",\n",
    "    conf_sweep=(0.05, 0.10, 0.20, 0.30, 0.40),\n",
    "    iou_sweep=(0.30, 0.50),\n",
    "    save_to: Path = None,\n",
    "    debug_report: Path = None\n",
    "):\n",
    "    \"\"\"Try multiple (conf, IoU) settings until we get matches.\"\"\"\n",
    "    data = load_yaml(data_yaml)\n",
    "    classes = data[\"names\"]; C = len(classes)\n",
    "    data_root = Path(data[\"path\"])\n",
    "    images_dir = data_root / f\"images/{split}\"\n",
    "    labels_dir = data_root / f\"labels/{split}\"\n",
    "    image_paths = sorted(list(images_dir.glob(\"*.*\")))\n",
    "    print(f\"[INFO] Confusion matrix over {len(image_paths)} images from {images_dir}\")\n",
    "\n",
    "    def make_cm(conf_thr, iou_thr):\n",
    "        y_true_all, y_pred_all = [], []\n",
    "        matches = 0\n",
    "        for img_path in image_paths:\n",
    "            w, h = imread_size(img_path)\n",
    "            gt_txt = labels_dir / (img_path.stem + \".txt\")\n",
    "            gt_boxes, gt_labels = yolo_txt_to_boxes(gt_txt, w, h)\n",
    "\n",
    "            r = model.predict(source=str(img_path), conf=conf_thr, iou=0.45, verbose=False)[0]\n",
    "            if r.boxes is None or len(r.boxes)==0:\n",
    "                pred_boxes = np.zeros((0,4), dtype=np.float32)\n",
    "                pred_cls   = np.zeros((0,), dtype=np.int32)\n",
    "            else:\n",
    "                pred_boxes = r.boxes.xyxy.cpu().numpy().astype(np.float32)\n",
    "                pred_cls   = r.boxes.cls.cpu().numpy().astype(np.int32)\n",
    "\n",
    "            if len(gt_boxes)==0 or len(pred_boxes)==0:\n",
    "                continue\n",
    "\n",
    "            iou_mat = box_iou_xyxy(gt_boxes, pred_boxes)\n",
    "            matched_gt, matched_pred = set(), set()\n",
    "            while iou_mat.size:\n",
    "                gi, pj = np.unravel_index(np.argmax(iou_mat), iou_mat.shape)\n",
    "                best = float(iou_mat[gi, pj])\n",
    "                if best < iou_thr: break\n",
    "                if gi in matched_gt or pj in matched_pred:\n",
    "                    iou_mat[gi, pj] = -1; continue\n",
    "                y_true_all.append(int(gt_labels[gi]))\n",
    "                y_pred_all.append(int(pred_cls[pj]))\n",
    "                matches += 1\n",
    "                matched_gt.add(gi); matched_pred.add(pj)\n",
    "                iou_mat[gi, :] = -1; iou_mat[:, pj] = -1\n",
    "        return matches, y_true_all, y_pred_all\n",
    "\n",
    "    found = False\n",
    "    picked = (None, None, None)\n",
    "    for conf_thr in conf_sweep:\n",
    "        for iou_thr in iou_sweep:\n",
    "            m, yt, yp = make_cm(conf_thr, iou_thr)\n",
    "            print(f\"[TRY] conf={conf_thr:.2f}, IoU={iou_thr:.2f} -> matches={m}\")\n",
    "            if m > 0:\n",
    "                found = True\n",
    "                picked = (conf_thr, iou_thr, (yt, yp))\n",
    "                break\n",
    "        if found: break\n",
    "\n",
    "    if not found:\n",
    "        # Write debug to help you inspect one or two images\n",
    "        if debug_report:\n",
    "            with open(debug_report, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"No matches found across sweeps. Debug sample:\\n\")\n",
    "                for img_path in image_paths[:10]:\n",
    "                    w, h = imread_size(img_path)\n",
    "                    gt_txt = labels_dir / (img_path.stem + \".txt\")\n",
    "                    gt_boxes, gt_labels = yolo_txt_to_boxes(gt_txt, w, h)\n",
    "                    f.write(f\"\\nImage: {img_path.name}, size={w}x{h}, GT count={len(gt_labels)}\\n\")\n",
    "                    try:\n",
    "                        r = model.predict(source=str(img_path), conf=0.05, iou=0.45, verbose=False)[0]\n",
    "                        if r.boxes is None or len(r.boxes)==0:\n",
    "                            f.write(\"  Pred: 0 boxes\\n\")\n",
    "                        else:\n",
    "                            cls = r.boxes.cls.cpu().numpy().astype(int)\n",
    "                            f.write(f\"  Pred: {len(cls)} boxes, class histogram: {Counter(cls)}\\n\")\n",
    "                    except Exception as e:\n",
    "                        f.write(f\"  Pred error: {e}\\n\")\n",
    "            print(f\"[DEBUG] Wrote {debug_report}\")\n",
    "        raise RuntimeError(\"No matches were found even after sweeping thresholds. \"\n",
    "                           \"Likely causes: undertrained model (5 epochs), label/path mismatch, or wrong class IDs.\")\n",
    "\n",
    "    conf_thr, iou_thr, (y_true_all, y_pred_all) = picked\n",
    "    print(f\"[USE] Using conf={conf_thr:.2f}, IoU={iou_thr:.2f} with {len(y_true_all)} matches.\")\n",
    "    cm = confusion_matrix(y_true_all, y_pred_all, labels=list(range(C)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"Confusion Matrix (Val) @conf={conf_thr:.2f}, IoU={iou_thr:.2f}\")\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks(range(C)); ax.set_yticks(range(C))\n",
    "    ax.set_xticklabels(classes, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(classes)\n",
    "    vmax = cm.max() if cm.size else 1\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            ax.text(j, i, str(cm[i,j]), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i,j] > 0.6*vmax else \"black\")\n",
    "    fig.tight_layout()\n",
    "    save_to = save_to or (OUT_DIR / \"confusion_matrix.png\")\n",
    "    fig.savefig(save_to, dpi=200); plt.close(fig)\n",
    "    print(f\"[OK] Confusion matrix saved → {save_to}\")\n",
    "\n",
    "# =========================\n",
    "# Train, Eval, Plot\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    assert DATA_YAML.exists(), f\"YAML not found at {DATA_YAML}. Run the prep script first.\"\n",
    "\n",
    "    # ---------- Sanity check data ----------\n",
    "    data_cfg = load_yaml(DATA_YAML)\n",
    "    class_names = data_cfg.get(\"names\", [\"helmet\",\"no_helmet\"])\n",
    "    class_count_expected = len(class_names)\n",
    "    _ = dataset_sanity_check(DATA_YAML, split=\"val\", class_count_expected=class_count_expected)\n",
    "\n",
    "    # ---------- Train (5 epochs) ----------\n",
    "    print(\"[INFO] Starting training (5 epochs)...\")\n",
    "    model = YOLO(BASE_MODEL)\n",
    "    train_res = model.train(\n",
    "        data=str(DATA_YAML),\n",
    "        imgsz=IMG,\n",
    "        epochs=EPOCHS,     # 5 epochs\n",
    "        batch=BATCH,\n",
    "        workers=WORKERS,\n",
    "        name=RUN_NAME,\n",
    "        project=str(ROOT / \"runs\" / \"detect\"),\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Locate the run directory robustly\n",
    "    save_dir = None\n",
    "    try:\n",
    "        save_dir = Path(getattr(model.trainer, \"save_dir\", None)) if hasattr(model, \"trainer\") else None\n",
    "    except Exception:\n",
    "        save_dir = None\n",
    "    if not save_dir or not save_dir.exists():\n",
    "        candidates = sorted(glob.glob(str(ROOT / f\"runs/detect/{RUN_NAME}*\")), key=os.path.getmtime)\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(\"Could not locate the training run directory. Check runs/detect/\")\n",
    "        save_dir = Path(candidates[-1])\n",
    "\n",
    "    print(f\"[INFO] Run directory: {save_dir}\")\n",
    "\n",
    "    weights_best = save_dir / \"weights\" / \"best.pt\"\n",
    "    if not weights_best.exists():\n",
    "        raise FileNotFoundError(f\"best.pt not found at {weights_best}. Training may have failed or not completed.\")\n",
    "\n",
    "    # ---------- Validate / Produce results.csv ----------\n",
    "    print(\"[INFO] Validating best.pt...\")\n",
    "    _ = model.val(data=str(DATA_YAML), split=\"val\", conf=0.25, iou=0.50, plots=True, verbose=True)\n",
    "\n",
    "    results_csv = save_dir / \"results.csv\"\n",
    "    if not results_csv.exists():\n",
    "        print(\"[WARN] results.csv missing; generating a compact metrics CSV by sweeping thresholds.\")\n",
    "        thresholds = [0.05,0.10,0.15,0.20,0.25,0.35,0.50,0.65,0.75]\n",
    "        rows = []\n",
    "        for thr in thresholds:\n",
    "            res = model.val(data=str(DATA_YAML), split=\"val\", conf=thr, iou=0.50, plots=False, verbose=False)\n",
    "            rd = getattr(res, \"results_dict\", {}) or {}\n",
    "            mp  = rd.get(\"metrics/precision(B)\")\n",
    "            mr  = rd.get(\"metrics/recall(B)\")\n",
    "            m50 = rd.get(\"metrics/mAP50(B)\") or rd.get(\"metrics/mAP_0.5\")\n",
    "            m95 = rd.get(\"metrics/mAP50-95(B)\") or rd.get(\"metrics/mAP_0.5:0.95\")\n",
    "            mets = getattr(res, \"metrics\", None)\n",
    "            if mets:\n",
    "                if m50 is None and hasattr(mets, \"box\") and hasattr(mets.box, \"map50\"):\n",
    "                    m50 = float(mets.box.map50)\n",
    "                if m95 is None and hasattr(mets, \"box\") and hasattr(mets.box, \"map\"):\n",
    "                    m95 = float(mets.box.map)\n",
    "                if mp is None and hasattr(mets, \"precision\"):\n",
    "                    mp = float(mets.precision)\n",
    "                if mr is None and hasattr(mets, \"recall\"):\n",
    "                    mr = float(mets.recall)\n",
    "            rows.append({\n",
    "                \"thr\": thr,\n",
    "                \"precision\": float(mp) if mp is not None else np.nan,\n",
    "                \"recall\": float(mr) if mr is not None else np.nan,\n",
    "                \"mAP50\": float(m50) if m50 is not None else np.nan,\n",
    "                \"mAP50-95\": float(m95) if m95 is not None else np.nan,\n",
    "            })\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(results_csv, index=False)\n",
    "        print(f\"[OK] Generated {results_csv}\")\n",
    "\n",
    "    # ---------- Plot curves ----------\n",
    "    df = pd.read_csv(results_csv)\n",
    "    rename_map = {\n",
    "        \"metrics/precision(B)\": \"precision\",\n",
    "        \"metrics/recall(B)\": \"recall\",\n",
    "        \"metrics/mAP50(B)\": \"mAP50\",\n",
    "        \"metrics/mAP50-95(B)\": \"mAP50-95\",\n",
    "    }\n",
    "    for k, v in rename_map.items():\n",
    "        if k in df.columns and v not in df.columns:\n",
    "            df[v] = df[k]\n",
    "    plot_curves_from_df(df, OUT_DIR / \"accuracy_curves.png\")\n",
    "\n",
    "    # ---------- Confusion matrix (resilient sweep) ----------\n",
    "    best_model = YOLO(str(weights_best))\n",
    "    run_confusion_heatmap_resilient(\n",
    "        model=best_model,\n",
    "        data_yaml=DATA_YAML,\n",
    "        split=\"val\",\n",
    "        conf_sweep=(0.05, 0.10, 0.20, 0.30, 0.40),\n",
    "        iou_sweep=(0.30, 0.50),\n",
    "        save_to=OUT_DIR / \"confusion_matrix.png\",\n",
    "        debug_report=OUT_DIR / \"no_matches_debug.txt\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n[DONE]\")\n",
    "    print(f\" - Weights:        {weights_best}\")\n",
    "    print(f\" - Results CSV:    {results_csv}\")\n",
    "    print(f\" - Curves:         {OUT_DIR / 'accuracy_curves.png'}\")\n",
    "    print(f\" - Confusion map:  {OUT_DIR / 'confusion_matrix.png'}\")\n",
    "    print(f\" - Debug (if any): {OUT_DIR / 'no_matches_debug.txt'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641bbb5-809c-4ea0-a6d0-8e7f97a1120a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
